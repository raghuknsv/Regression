
library(lmtest)
library(readxl)
library(data.table)
library(pscl)
library(car)
library(lmtest)
library(survey)
library(ggplot2)
library(leaps)
library(reshape2)
library(car)
library(lattice)
library(ROCR)
library(corrgram)
library(ggplot2)


##Loading The dataset

{r, error=FALSE, warning=FALSE}
library(readxl)


DBS <- read_excel("~/Downloads/titanic3.xls")
View(DBS)


###Checking the dimensions of the data set

dim(DBS)
str(DBS)


#Data Preprocessing

##Checking for null values

sapply(DBS,function(x) sum(is.na(x)))


#As we can see from the above table, attributes, faare, cabin, embarked, boat, body and home destination have missing values. We will not use cabin, boat and body variables since they have too many missing values.

####Removing the null values

DBS$age[is.na(DBS$age)] <- mean(DBS$age,na.rm=T)

DBS <- DBS[!is.na(DBS$embarked),]
rownames(DBS) <- NULL

is.factor(DBS$sex)
is.factor(DBS$embarked)
is.factor(DBS$survived)

dim(DBS)
str(DBS)

DBS$name=NULL
DBS$body=NULL
DBS$cabin=NULL
DBS$home.dest=NULL
DBS$boat=NULL
DBS$ticket=NULL

DBS$fare[is.na(DBS$fare)] <- mean(DBS$fare,na.rm=T)
sapply(DBS,function(x) sum(is.na(x)))

#As we can see above the data is cleaned and there are no missing values.

###Converting the required catagorical variables into factor variables.

DBS$survived<-as.factor(DBS$survived)
DBS$sex<-as.factor(DBS$sex)
DBS$embarked<-as.factor(DBS$embarked)
DBS

levels(DBS$embarked)
levels(DBS$survived)
levels(DBS$sex)

#Modeling

###Spliting the data for training and testing

dim(DBS)
samplesize = floor(0.7 * nrow(DBS))
samplesize

#We have taken a sample size of 914 observations out of 1307 i.e. 70% of the dataset.

set.seed(1600)
train_set = sample(seq_len(nrow(DBS)), size = samplesize)


###Traing and testing dataset
training = DBS[train_set, ]
testing = DBS[-train_set, ]

#We have spllit the data into trainging and testing datasets. We will be using the trainging dataset to fit a model.

###Checking the dimenssions.

dim(training)
dim(testing)


##Applying the model for the training dataset

#We will be using glm() function to perform binomial logistic regression. The target vaiable has two levels. By using the target variable, we will be finding the significance of each variable. Below is the code to perform the task.

model<-glm(survived~.,family=binomial(link="logit"),data=training)
summary(model)


#From the above table, we can see that parch, Fare and Embarked are not statistically significant. Thus we will have to run the model again to remove these attributes. 

#Sex has the lowest p-value suggesting a strong association of the sex of the passenger with the probability of having survived. A male passenger is less likely to have survived. 


###Data visualization

newdata<-data.frame(fitted=model$fitted.values, residuals=model$residuals, Outcome=training$survived )
plot<-ggplot(data=newdata, aes(x=fitted, y=residuals, colour=factor(training$survived)))
plot + geom_point(size=4)



###Removing the variable with the heighest significance

model.final1<-glm(survived~pclass+sex+age+sibsp+parch+fare,data=training,family = binomial(link="logit"))
summary(model.final1)


#From the above table we can see that, attribute parch has a high P value and is not statistically significant, thus, we will have to perform the model again.

###Removing attribute perch

model.final<-glm(survived~pclass+sex+age+sibsp+fare,data=training,family = binomial(link="logit"))
summary(model.final)


#From above we can see that all of the variables are statistically significant. Now we can use this model to predict the accuracy of the model.



###Histograms of all the variables

gg1 <- melt(DBS)
ggplot(gg1, aes(x=value, fill=variable)) +
  geom_histogram(binwidth=5)+
  facet_wrap(~variable)


###Prediction

pred1 <- predict(model.final, newdata = testing, type = "response")
prediction_testing = predict(model.final,testing, type = "response")
prediction_testing = ifelse(prediction_testing > 0.5, 1, 0)
error = mean(prediction_testing != testing$survived)
print(paste('Model Accuracy',1-error))


#The above model has an accuracy of 79.13%. This is a vary high accuracy rate. As a last step, we are going to plot the ROC curve and calculate the AUC (area under the curve) which are typical performance measurements for a binary classifier.

###ROC plot

#The ROC is a curve generated by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.

pr = prediction(pred1, testing$survived)
prf = performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)


###AUC

#The AUC is the area under the ROC curve. A model is said to have a good predictive ability if it has an AUC closer to 1 (1 is ideal) than to 0.5.

auc = performance(pr, measure = "auc")
auc = auc@y.values[[1]]
print(paste("Model Accuracy", auc))


#Since the accuracy is 0.833 and is very close to 1, we can say that this model has a good predictive ability.

deviance(model.final)
pchisq(model.final$deviance, df=model.final$df.residual, lower.tail=FALSE)


#The p-value gives the goodness of fit. The null hypothesis states that model fits well and alternative
#hypothesis states that model doesnt fit the data. So according to the value it indicates that null hypothesis is plausible and we can conclude that, logistic model is adequate.

#Conclusion

#By performing the above alalysis, we get to know that, for the selected dataset, generalized linear model is the best model to fit. We get to know that sex and passenger class have the heghest significance. People with a heigher passenger class and who are female have the heighest chance for survival. The selected model has an accuracy of 79.2%. This is a very high percentage and show that it is a good model with a good predictive ability.

